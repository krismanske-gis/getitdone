{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51f3f69-1384-4b7c-a3ec-9f7b15b6897f",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "This notebook is run after \"01_import_CPA_boundaries.ipynb\"\n",
    "\n",
    "# INPUT\n",
    "It is looking from CSV downloaded from Get It Done website.\n",
    "\n",
    "# OUTPUT\n",
    "Drainage related requests that have passed basic QA: gid_drainage_candidate_last30.csv \n",
    "Records without address or coordinates which need to be reviewed: gid_drainage_review_last30.csv rows: 30\n",
    "\n",
    "This notebook has the following steps:\n",
    "- Use pandas to import the Get It Done complaints from the city of San Diego, pulling the last month of data\n",
    "- Filter them to drainage-related data\n",
    "- Do some minor address cleanup\n",
    "- Check for any outlying data points outside San Diego or rows with missing coordinates\n",
    "- Standardize address and coordinate cleanup status message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d96122b-90f2-4e3c-9196-d5cecc376f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: C:\\Users\\kris_\\OneDrive - Kris Manske\\Documents\\Classes\\BootcampGIS\\Wildfire repositories on AWS\\GetItDone\\data_raw\\get_it_done_requests_open_datasd.csv\n",
      "GDB: C:\\Users\\kris_\\OneDrive - Kris Manske\\Documents\\Classes\\BootcampGIS\\Wildfire repositories on AWS\\GetItDone\\data_working\\GetItDoneAnalysis.gdb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import arcpy\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "PROJECT_ROOT = r\"C:\\Users\\kris_\\OneDrive - Kris Manske\\Documents\\Classes\\BootcampGIS\\Wildfire repositories on AWS\\GetItDone\"\n",
    "\n",
    "\n",
    "RAW_DIR = os.path.join(PROJECT_ROOT, \"data_raw\")\n",
    "WORK_DIR = os.path.join(PROJECT_ROOT, \"data_working\")\n",
    "GDB_PATH = os.path.join(WORK_DIR, \"GetItDoneAnalysis.gdb\")\n",
    "\n",
    "# Inputs\n",
    "GETITDONE_CSV = os.path.join(RAW_DIR, \"get_it_done_requests_open_datasd.csv\")  # your file name\n",
    "\n",
    "# Optional: set workspace for easier listing\n",
    "arcpy.env.workspace = GDB_PATH\n",
    "\n",
    "for p in [GETITDONE_CSV]:\n",
    "    if not os.path.exists(p) and not arcpy.Exists(p):\n",
    "        raise FileNotFoundError(f\"Missing required input: {p}\")\n",
    "\n",
    "print(\"CSV:\", GETITDONE_CSV)\n",
    "print(\"GDB:\", GDB_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e4e83b4-de3e-4cd2-88c2-aaa39fba95bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 87693\n",
      "Columns: ['service_request_id', 'service_request_parent_id', 'sap_notification_number', 'date_requested', 'case_age_days', 'case_record_type', 'service_name', 'service_name_detail', 'date_closed', 'status', 'lat', 'lng', 'street_address', 'zipcode', 'council_district', 'comm_plan_code', 'comm_plan_name', 'park_name', 'case_origin', 'referred', 'iamfloc', 'floc', 'public_description']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>service_request_parent_id</th>\n",
       "      <th>sap_notification_number</th>\n",
       "      <th>date_requested</th>\n",
       "      <th>case_age_days</th>\n",
       "      <th>case_record_type</th>\n",
       "      <th>service_name</th>\n",
       "      <th>service_name_detail</th>\n",
       "      <th>date_closed</th>\n",
       "      <th>status</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>council_district</th>\n",
       "      <th>comm_plan_code</th>\n",
       "      <th>comm_plan_name</th>\n",
       "      <th>park_name</th>\n",
       "      <th>case_origin</th>\n",
       "      <th>referred</th>\n",
       "      <th>iamfloc</th>\n",
       "      <th>floc</th>\n",
       "      <th>public_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.030001e+10</td>\n",
       "      <td>2016-08-20T14:46:00</td>\n",
       "      <td>3435</td>\n",
       "      <td>TSW</td>\n",
       "      <td>Street Sweeping</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Process</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Mid-City:City Heights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS-014304</td>\n",
       "      <td>SS-001240</td>\n",
       "      <td>A)  The storm drain channel south of 5135 Univ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.030001e+10</td>\n",
       "      <td>2016-08-20T15:48:00</td>\n",
       "      <td>3435</td>\n",
       "      <td>TSW</td>\n",
       "      <td>Sidewalk Repair Issue</td>\n",
       "      <td>SIDEWALK MINOR REHAB CONTRACT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Process</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Mid-City:Normal Heights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS-000917-SE1</td>\n",
       "      <td>SS-000917</td>\n",
       "      <td>Curb in rubble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.030001e+10</td>\n",
       "      <td>2016-08-22T10:04:00</td>\n",
       "      <td>3433</td>\n",
       "      <td>TSW</td>\n",
       "      <td>Stormwater</td>\n",
       "      <td>DRAIN HEADWALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Process</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Mira Mesa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HW01082</td>\n",
       "      <td>SS-019619</td>\n",
       "      <td>HILLSIDE ERODING - POSSIBLE BROKEN DRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   service_request_id  service_request_parent_id  sap_notification_number  \\\n",
       "0              100763                        NaN             4.030001e+10   \n",
       "1              100777                        NaN             4.030001e+10   \n",
       "2              100985                        NaN             4.030001e+10   \n",
       "\n",
       "        date_requested  case_age_days case_record_type           service_name  \\\n",
       "0  2016-08-20T14:46:00           3435              TSW        Street Sweeping   \n",
       "1  2016-08-20T15:48:00           3435              TSW  Sidewalk Repair Issue   \n",
       "2  2016-08-22T10:04:00           3433              TSW             Stormwater   \n",
       "\n",
       "             service_name_detail  date_closed      status  ...  zipcode  \\\n",
       "0                            NaN          NaN  In Process  ...      NaN   \n",
       "1  SIDEWALK MINOR REHAB CONTRACT          NaN  In Process  ...      NaN   \n",
       "2                 DRAIN HEADWALL          NaN  In Process  ...      NaN   \n",
       "\n",
       "   council_district comm_plan_code           comm_plan_name  park_name  \\\n",
       "0               9.0           56.0    Mid-City:City Heights        NaN   \n",
       "1               9.0           59.0  Mid-City:Normal Heights        NaN   \n",
       "2               6.0           15.0                Mira Mesa        NaN   \n",
       "\n",
       "   case_origin referred        iamfloc       floc  \\\n",
       "0          Web      NaN      SS-014304  SS-001240   \n",
       "1          Web      NaN  SS-000917-SE1  SS-000917   \n",
       "2        Phone      NaN        HW01082  SS-019619   \n",
       "\n",
       "                                  public_description  \n",
       "0  A)  The storm drain channel south of 5135 Univ...  \n",
       "1                                     Curb in rubble  \n",
       "2           HILLSIDE ERODING - POSSIBLE BROKEN DRAIN  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(GETITDONE_CSV)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebc989d8-2210-41e1-b0ac-c25539511302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drainage candidate rows: 3358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "service_name\n",
       "Stormwater                     2276\n",
       "Stormwater Code Enforcement     962\n",
       "ROW Maintenance                 117\n",
       "Parks Issue                       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase helper columns\n",
    "df[\"service_name_lc\"] = df[\"service_name\"].astype(str).str.lower()\n",
    "df[\"service_detail_lc\"] = df[\"service_name_detail\"].astype(str).str.lower()\n",
    "\n",
    "# Start broad, refine later\n",
    "drainage_mask = (\n",
    "    df[\"service_name_lc\"].str.contains(\"storm\", na=False) |\n",
    "    df[\"service_name_lc\"].str.contains(\"drain\", na=False) |\n",
    "    df[\"service_detail_lc\"].str.contains(\"storm\", na=False) |\n",
    "    df[\"service_detail_lc\"].str.contains(\"drain\", na=False) |\n",
    "    df[\"service_detail_lc\"].str.contains(\"flood\", na=False)\n",
    ")\n",
    "\n",
    "dr = df[drainage_mask].copy()\n",
    "print(\"Drainage candidate rows:\", len(dr))\n",
    "\n",
    "# Peek at the most common categories to tighten the filter\n",
    "dr[\"service_name\"].value_counts().head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7c4ffb-da22-4b5c-b592-e88b62ff9c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing coords: 27\n",
      "Missing address: 0\n",
      "Coords out of range: 30\n"
     ]
    }
   ],
   "source": [
    "# Ensure numeric\n",
    "dr[\"lat_num\"] = pd.to_numeric(dr[\"lat\"], errors=\"coerce\")\n",
    "dr[\"lng_num\"] = pd.to_numeric(dr[\"lng\"], errors=\"coerce\")\n",
    "\n",
    "dr[\"qa_missing_coords\"] = dr[\"lat_num\"].isna() | dr[\"lng_num\"].isna()\n",
    "dr[\"qa_missing_address\"] = dr[\"street_address\"].isna() | (dr[\"street_address\"].astype(str).str.strip() == \"\")\n",
    "\n",
    "# Basic plausible range check (San Diego-ish bounding box)\n",
    "# (This is a quick sanity check, not a precise boundary test)\n",
    "dr[\"qa_coords_out_of_range\"] = ~(\n",
    "    dr[\"lat_num\"].between(32.5, 33.2, inclusive=\"both\") &\n",
    "    dr[\"lng_num\"].between(-117.4, -116.8, inclusive=\"both\")\n",
    ")\n",
    "\n",
    "print(\"Missing coords:\", int(dr[\"qa_missing_coords\"].sum()))\n",
    "print(\"Missing address:\", int(dr[\"qa_missing_address\"].sum()))\n",
    "print(\"Coords out of range:\", int(dr[\"qa_coords_out_of_range\"].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "563e65fb-f67e-4bbc-81a5-294ce306f2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QA_STATUS\n",
       "OK                3328\n",
       "MISSING_COORDS      27\n",
       "OUT_OF_RANGE         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a status message showing errors found in the rows (if any)\n",
    "def qa_status(row):\n",
    "    if row[\"qa_missing_coords\"]:\n",
    "        return \"MISSING_COORDS\"\n",
    "    if row[\"qa_coords_out_of_range\"]:\n",
    "        return \"OUT_OF_RANGE\"\n",
    "    if row[\"qa_missing_address\"]:\n",
    "        return \"MISSING_ADDRESS\"\n",
    "    return \"OK\"\n",
    "\n",
    "dr[\"QA_STATUS\"] = dr.apply(qa_status, axis=1)\n",
    "\n",
    "# quick check\n",
    "dr[\"QA_STATUS\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198a519b-9867-437b-a0b1-0e8322bc4d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate for CPA join: 3328\n",
      "Review (missing/out-of-range): 30\n"
     ]
    }
   ],
   "source": [
    "# Good enough to attempt CPA join: has coords and coords are plausible\n",
    "dr[\"qa_join_candidate\"] = (~dr[\"qa_missing_coords\"]) & (~dr[\"qa_coords_out_of_range\"])\n",
    "\n",
    "# Everything else is \"review\"\n",
    "dr_review = dr[~dr[\"qa_join_candidate\"]].copy()\n",
    "dr_candidate = dr[dr[\"qa_join_candidate\"]].copy()\n",
    "\n",
    "print(\"Candidate for CPA join:\", len(dr_candidate))\n",
    "print(\"Review (missing/out-of-range):\", len(dr_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21abd008-388c-4e7f-a096-d97761f73655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic cleanup of punctuation and addresses\n",
    "dr[\"street_address_clean\"] = (\n",
    "    dr[\"street_address\"]\n",
    "    .astype(str)\n",
    "    .str.upper()\n",
    "    # Find every period (.) in the string and remove it\n",
    "    .str.replace(r\"\\.\", \"\", regex=True)\n",
    "    # Replace any run of multiple spaces, tabs, or line breaks with a single space\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a63b676-5431-41ed-aa78-f9add24bf004",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\kris_\\\\OneDrive - Kris Manske\\\\Documents\\\\Classes\\\\BootcampGIS\\\\Wildfire repositories on AWS\\\\GetItDone\\\\data_working\\\\gid_drainage_candidate_last30.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     out[keep]\u001b[38;5;241m.\u001b[39mto_csv(out_csv, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrote:\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_csv, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(out))\n\u001b[1;32m---> 20\u001b[0m export_for_xy(dr_candidate, CANDIDATE_CSV)\n\u001b[0;32m     21\u001b[0m export_for_xy(dr_review, REVIEW_CSV)\n",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m, in \u001b[0;36mexport_for_xy\u001b[1;34m(df_in, out_csv)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Keep desired columns; make sure QA_STATUS is included\u001b[39;00m\n\u001b[0;32m     11\u001b[0m keep \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_request_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_name_detail\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublic_description\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_requested\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstreet_address\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstreet_address_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQA_STATUS\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m ] \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39mcolumns] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m out[keep]\u001b[38;5;241m.\u001b[39mto_csv(out_csv, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrote:\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_csv, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(out))\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\kris_\\\\OneDrive - Kris Manske\\\\Documents\\\\Classes\\\\BootcampGIS\\\\Wildfire repositories on AWS\\\\GetItDone\\\\data_working\\\\gid_drainage_candidate_last30.csv'"
     ]
    }
   ],
   "source": [
    "# Write two CSV files - one that has records with coordinates, and one to be reviewed that doesn't\n",
    "\n",
    "CANDIDATE_CSV = os.path.join(WORK_DIR, \"gid_drainage_candidate_last30.csv\")\n",
    "REVIEW_CSV = os.path.join(WORK_DIR, \"gid_drainage_review_last30.csv\")\n",
    "\n",
    "def export_for_xy(df_in, out_csv):\n",
    "    out = df_in.copy()\n",
    "    out[\"lat\"] = pd.to_numeric(out[\"lat\"], errors=\"coerce\")\n",
    "    out[\"lon\"] = pd.to_numeric(out[\"lng\"], errors=\"coerce\")  # adjust if lng field name differs\n",
    "    # Keep desired columns; make sure QA_STATUS is included\n",
    "    keep = [c for c in [\n",
    "        \"service_request_id\", \"service_name\", \"service_name_detail\",\n",
    "        \"public_description\", \"date_requested\", \"status\",\n",
    "        \"street_address\", \"street_address_clean\",\n",
    "        \"QA_STATUS\"\n",
    "    ] if c in out.columns] + [\"lat\", \"lon\"]\n",
    "    out[keep].to_csv(out_csv, index=False)\n",
    "    print(\"Wrote:\", out_csv, \"rows:\", len(out))\n",
    "\n",
    "export_for_xy(dr_candidate, CANDIDATE_CSV)\n",
    "export_for_xy(dr_review, REVIEW_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74794e-8abc-4581-a2b5-c0ba6fd2dfad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
