{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51f3f69-1384-4b7c-a3ec-9f7b15b6897f",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "This notebook is run after \"01_import_CPA_boundaries.ipynb\"\n",
    "It assumes there is a GitItDoneAnalysis GDB with a \"cpa_prj\" feature class showing community planning areas in San Diego (output from first notebook).\n",
    "\n",
    "This notebook has the following steps:\n",
    "- Use pandas to import the Get It Done complaints from the city of San Diego, pulling the last month of data\n",
    "- Filter them to drainage-related data\n",
    "- Do some minor address cleanup\n",
    "- Check for any outlying data points outside San Diego or rows with missing coordinates\n",
    "- Standardize address and coordinate cleanup status message\n",
    "- Create a feature class from the cleaned up data, then reproject it to match the cpa_proj\n",
    "- Do a spatial join - match the complaints to which CPA they lie in, so analysis can be performed by CPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96122b-90f2-4e3c-9196-d5cecc376f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import arcpy\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "PROJECT_ROOT = r\"C:\\Users\\kris_\\OneDrive - Kris Manske\\Documents\\Classes\\BootcampGIS\\Wildfire repositories on AWS\\GetItDone\"\n",
    "\n",
    "\n",
    "RAW_DIR = os.path.join(PROJECT_ROOT, \"data_raw\")\n",
    "WORK_DIR = os.path.join(PROJECT_ROOT, \"data_working\")\n",
    "GDB_PATH = os.path.join(WORK_DIR, \"GetItDoneAnalysis.gdb\")\n",
    "\n",
    "# Inputs\n",
    "GETITDONE_CSV = os.path.join(RAW_DIR, \"get_it_done_requests_open_datasd.csv\")  # your file name\n",
    "CPA_FC = os.path.join(GDB_PATH, \"cpa_prj\")  # from Notebook 1\n",
    "\n",
    "# Outputs\n",
    "DRAINAGE_CSV = os.path.join(WORK_DIR, \"gid_drainage_clean.csv\")\n",
    "DRAINAGE_POINTS_FC = os.path.join(GDB_PATH, \"gid_drainage_points_clean\")\n",
    "DRAINAGE_BY_CPA_FC = os.path.join(GDB_PATH, \"gid_drainage_by_cpa\")\n",
    "\n",
    "# Optional: set workspace for easier listing\n",
    "arcpy.env.workspace = GDB_PATH\n",
    "\n",
    "for p in [GETITDONE_CSV, CPA_FC]:\n",
    "    if not os.path.exists(p) and not arcpy.Exists(p):\n",
    "        raise FileNotFoundError(f\"Missing required input: {p}\")\n",
    "\n",
    "print(\"CSV:\", GETITDONE_CSV)\n",
    "print(\"CPA:\", CPA_FC)\n",
    "print(\"GDB:\", GDB_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e4e83b4-de3e-4cd2-88c2-aaa39fba95bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 87693\n",
      "Columns: ['service_request_id', 'service_request_parent_id', 'sap_notification_number', 'date_requested', 'case_age_days', 'case_record_type', 'service_name', 'service_name_detail', 'date_closed', 'status', 'lat', 'lng', 'street_address', 'zipcode', 'council_district', 'comm_plan_code', 'comm_plan_name', 'park_name', 'case_origin', 'referred', 'iamfloc', 'floc', 'public_description']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>service_request_parent_id</th>\n",
       "      <th>sap_notification_number</th>\n",
       "      <th>date_requested</th>\n",
       "      <th>case_age_days</th>\n",
       "      <th>case_record_type</th>\n",
       "      <th>service_name</th>\n",
       "      <th>service_name_detail</th>\n",
       "      <th>date_closed</th>\n",
       "      <th>status</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>council_district</th>\n",
       "      <th>comm_plan_code</th>\n",
       "      <th>comm_plan_name</th>\n",
       "      <th>park_name</th>\n",
       "      <th>case_origin</th>\n",
       "      <th>referred</th>\n",
       "      <th>iamfloc</th>\n",
       "      <th>floc</th>\n",
       "      <th>public_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.030001e+10</td>\n",
       "      <td>2016-08-20T14:46:00</td>\n",
       "      <td>3435</td>\n",
       "      <td>TSW</td>\n",
       "      <td>Street Sweeping</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Process</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Mid-City:City Heights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS-014304</td>\n",
       "      <td>SS-001240</td>\n",
       "      <td>A)  The storm drain channel south of 5135 Univ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.030001e+10</td>\n",
       "      <td>2016-08-20T15:48:00</td>\n",
       "      <td>3435</td>\n",
       "      <td>TSW</td>\n",
       "      <td>Sidewalk Repair Issue</td>\n",
       "      <td>SIDEWALK MINOR REHAB CONTRACT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Process</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Mid-City:Normal Heights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS-000917-SE1</td>\n",
       "      <td>SS-000917</td>\n",
       "      <td>Curb in rubble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.030001e+10</td>\n",
       "      <td>2016-08-22T10:04:00</td>\n",
       "      <td>3433</td>\n",
       "      <td>TSW</td>\n",
       "      <td>Stormwater</td>\n",
       "      <td>DRAIN HEADWALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Process</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Mira Mesa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HW01082</td>\n",
       "      <td>SS-019619</td>\n",
       "      <td>HILLSIDE ERODING - POSSIBLE BROKEN DRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   service_request_id  service_request_parent_id  sap_notification_number  \\\n",
       "0              100763                        NaN             4.030001e+10   \n",
       "1              100777                        NaN             4.030001e+10   \n",
       "2              100985                        NaN             4.030001e+10   \n",
       "\n",
       "        date_requested  case_age_days case_record_type           service_name  \\\n",
       "0  2016-08-20T14:46:00           3435              TSW        Street Sweeping   \n",
       "1  2016-08-20T15:48:00           3435              TSW  Sidewalk Repair Issue   \n",
       "2  2016-08-22T10:04:00           3433              TSW             Stormwater   \n",
       "\n",
       "             service_name_detail  date_closed      status  ...  zipcode  \\\n",
       "0                            NaN          NaN  In Process  ...      NaN   \n",
       "1  SIDEWALK MINOR REHAB CONTRACT          NaN  In Process  ...      NaN   \n",
       "2                 DRAIN HEADWALL          NaN  In Process  ...      NaN   \n",
       "\n",
       "   council_district comm_plan_code           comm_plan_name  park_name  \\\n",
       "0               9.0           56.0    Mid-City:City Heights        NaN   \n",
       "1               9.0           59.0  Mid-City:Normal Heights        NaN   \n",
       "2               6.0           15.0                Mira Mesa        NaN   \n",
       "\n",
       "   case_origin referred        iamfloc       floc  \\\n",
       "0          Web      NaN      SS-014304  SS-001240   \n",
       "1          Web      NaN  SS-000917-SE1  SS-000917   \n",
       "2        Phone      NaN        HW01082  SS-019619   \n",
       "\n",
       "                                  public_description  \n",
       "0  A)  The storm drain channel south of 5135 Univ...  \n",
       "1                                     Curb in rubble  \n",
       "2           HILLSIDE ERODING - POSSIBLE BROKEN DRAIN  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(GETITDONE_CSV)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "136f8c7c-9209-4329-9037-359b761a6ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff date (same day last month): 2025-12-17\n",
      "Recent rows: 14687\n",
      "Date range: 2025-12-17 02:14:00 to 2026-01-15 22:54:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parse request date\n",
    "df[\"date_requested_dt\"] = pd.to_datetime(df[\"date_requested\"], errors=\"coerce\")\n",
    "\n",
    "# Cutoff = same calendar day last month\n",
    "cutoff = pd.Timestamp.today().normalize() - pd.DateOffset(months=1)\n",
    "\n",
    "print(\"Cutoff date (same day last month):\", cutoff.date())\n",
    "\n",
    "# Filter to records on/after cutoff\n",
    "df_recent = df[df[\"date_requested_dt\"] >= cutoff].copy()\n",
    "\n",
    "print(\"Recent rows:\", len(df_recent))\n",
    "print(\n",
    "    \"Date range:\",\n",
    "    df_recent[\"date_requested_dt\"].min(),\n",
    "    \"to\",\n",
    "    df_recent[\"date_requested_dt\"].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc989d8-2210-41e1-b0ac-c25539511302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drainage candidate rows: 3358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "service_name\n",
       "Stormwater                     2276\n",
       "Stormwater Code Enforcement     962\n",
       "ROW Maintenance                 117\n",
       "Parks Issue                       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase helper columns\n",
    "df[\"service_name_lc\"] = df[\"service_name\"].astype(str).str.lower()\n",
    "df[\"service_detail_lc\"] = df[\"service_name_detail\"].astype(str).str.lower()\n",
    "\n",
    "# Start broad, refine later\n",
    "drainage_mask = (\n",
    "    df[\"service_name_lc\"].str.contains(\"storm\", na=False) |\n",
    "    df[\"service_name_lc\"].str.contains(\"drain\", na=False) |\n",
    "    df[\"service_detail_lc\"].str.contains(\"storm\", na=False) |\n",
    "    df[\"service_detail_lc\"].str.contains(\"drain\", na=False) |\n",
    "    df[\"service_detail_lc\"].str.contains(\"flood\", na=False)\n",
    ")\n",
    "\n",
    "dr = df[drainage_mask].copy()\n",
    "print(\"Drainage candidate rows:\", len(dr))\n",
    "\n",
    "# Peek at the most common categories to tighten the filter\n",
    "dr[\"service_name\"].value_counts().head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d7c4ffb-da22-4b5c-b592-e88b62ff9c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing coords: 27\n",
      "Missing address: 0\n",
      "Coords out of range: 30\n"
     ]
    }
   ],
   "source": [
    "# Ensure numeric\n",
    "dr[\"lat_num\"] = pd.to_numeric(dr[\"lat\"], errors=\"coerce\")\n",
    "dr[\"lng_num\"] = pd.to_numeric(dr[\"lng\"], errors=\"coerce\")\n",
    "\n",
    "dr[\"qa_missing_coords\"] = dr[\"lat_num\"].isna() | dr[\"lng_num\"].isna()\n",
    "dr[\"qa_missing_address\"] = dr[\"street_address\"].isna() | (dr[\"street_address\"].astype(str).str.strip() == \"\")\n",
    "\n",
    "# Basic plausible range check (San Diego-ish bounding box)\n",
    "# (This is a quick sanity check, not a precise boundary test)\n",
    "dr[\"qa_coords_out_of_range\"] = ~(\n",
    "    dr[\"lat_num\"].between(32.5, 33.2, inclusive=\"both\") &\n",
    "    dr[\"lng_num\"].between(-117.4, -116.8, inclusive=\"both\")\n",
    ")\n",
    "\n",
    "print(\"Missing coords:\", int(dr[\"qa_missing_coords\"].sum()))\n",
    "print(\"Missing address:\", int(dr[\"qa_missing_address\"].sum()))\n",
    "print(\"Coords out of range:\", int(dr[\"qa_coords_out_of_range\"].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "563e65fb-f67e-4bbc-81a5-294ce306f2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QA_STATUS\n",
       "OK                3328\n",
       "MISSING_COORDS      27\n",
       "OUT_OF_RANGE         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def qa_status(row):\n",
    "    if row[\"qa_missing_coords\"]:\n",
    "        return \"MISSING_COORDS\"\n",
    "    if row[\"qa_coords_out_of_range\"]:\n",
    "        return \"OUT_OF_RANGE\"\n",
    "    if row[\"qa_missing_address\"]:\n",
    "        return \"MISSING_ADDRESS\"\n",
    "    return \"OK\"\n",
    "\n",
    "dr[\"QA_STATUS\"] = dr.apply(qa_status, axis=1)\n",
    "\n",
    "# quick check\n",
    "dr[\"QA_STATUS\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21abd008-388c-4e7f-a096-d97761f73655",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr[\"street_address_clean\"] = (\n",
    "    dr[\"street_address\"]\n",
    "    .astype(str)\n",
    "    .str.upper()\n",
    "    .str.replace(r\"\\.\", \"\", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4041adc3-1076-4320-9277-74221ac766a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\Users\\kris_\\OneDrive - Kris Manske\\Documents\\Classes\\BootcampGIS\\Wildfire repositories on AWS\\GetItDone\\data_working\\gid_drainage_clean.csv rows: 3358\n"
     ]
    }
   ],
   "source": [
    "# Keep only what we need (add/remove fields as desired)\n",
    "keep_cols = [\n",
    "    \"service_request_id\", \"service_name\", \"service_name_detail\",\n",
    "    \"public_description\", \"date_requested\", \"status\",\n",
    "    \"street_address\", \"street_address_clean\",\n",
    "    \"lat_num\", \"lng_num\",\n",
    "    \"qa_missing_coords\", \"qa_missing_address\", \"qa_coords_out_of_range\", \"qa_status\",\n",
    "]\n",
    "\n",
    "# Some files may have different ID column names; adjust if needed after you inspect columns\n",
    "existing = [c for c in keep_cols if c in dr.columns]\n",
    "out = dr[existing].copy()\n",
    "\n",
    "# Rename coords to lat/lon fields ArcPy can read easily\n",
    "out = out.rename(columns={\"lat_num\": \"lat\", \"lng_num\": \"lon\"})\n",
    "\n",
    "out.to_csv(DRAINAGE_CSV, index=False)\n",
    "print(\"Wrote:\", DRAINAGE_CSV, \"rows:\", len(out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f4a3f-2033-493b-94d4-ba895e1b37ca",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "START OF SECTION I REMOVED FROM THE NEW 02 NOTEBOOK\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d68b222d-65f8-4a4e-a0ee-776421266773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created points FC: C:\\Users\\kris_\\OneDrive - Kris Manske\\Documents\\Classes\\BootcampGIS\\Wildfire repositories on AWS\\GetItDone\\data_working\\GetItDoneAnalysis.gdb\\gid_drainage_points_clean\n",
      "Point count: 3358\n"
     ]
    }
   ],
   "source": [
    "# Make an XY Event Layer from the CSV\n",
    "xy_layer = \"gid_drainage_xy\"\n",
    "\n",
    "# Spatial reference for incoming coords (WGS84)\n",
    "wgs84 = arcpy.SpatialReference(4326)\n",
    "\n",
    "# Create event layer\n",
    "arcpy.management.MakeXYEventLayer(\n",
    "    table=DRAINAGE_CSV,\n",
    "    in_x_field=\"lon\",\n",
    "    in_y_field=\"lat\",\n",
    "    out_layer=xy_layer,\n",
    "    spatial_reference=wgs84\n",
    ")\n",
    "\n",
    "# Copy to feature class in GDB\n",
    "if arcpy.Exists(DRAINAGE_POINTS_FC):\n",
    "    arcpy.management.Delete(DRAINAGE_POINTS_FC)\n",
    "\n",
    "arcpy.management.CopyFeatures(xy_layer, DRAINAGE_POINTS_FC)\n",
    "\n",
    "print(\"Created points FC:\", DRAINAGE_POINTS_FC)\n",
    "print(\"Point count:\", arcpy.management.GetCount(DRAINAGE_POINTS_FC)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e264340-f1e9-4cee-b7ea-979baa37ce5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created WGS84 points: C:\\Users\\kris_\\OneDrive - Kris Manske\\Documents\\Classes\\BootcampGIS\\Wildfire repositories on AWS\\GetItDone\\data_working\\GetItDoneAnalysis.gdb\\gid_drainage_points_wgs84\n",
      "Count: 3358\n",
      "Deleted temporary WGS84 feature class\n",
      "Projected points FC: C:\\Users\\kris_\\OneDrive - Kris Manske\\Documents\\Classes\\BootcampGIS\\Wildfire repositories on AWS\\GetItDone\\data_working\\GetItDoneAnalysis.gdb\\gid_drainage_points_clean\n",
      "Projected SR: NAD_1983_StatePlane_California_V_FIPS_0405_Feet\n"
     ]
    }
   ],
   "source": [
    "# Make an XY Event Layer from the CSV\n",
    "xy_layer = \"gid_drainage_xy\"\n",
    "\n",
    "# Spatial reference for incoming coords (lat/lon) = WGS84\n",
    "wgs84 = arcpy.SpatialReference(4326)\n",
    "\n",
    "arcpy.management.MakeXYEventLayer(\n",
    "    table=DRAINAGE_CSV,\n",
    "    in_x_field=\"lon\",\n",
    "    in_y_field=\"lat\",\n",
    "    out_layer=xy_layer,\n",
    "    spatial_reference=wgs84\n",
    ")\n",
    "\n",
    "# Copy to feature class in GDB (still WGS84)\n",
    "tmp_points_wgs84 = os.path.join(GDB_PATH, \"gid_drainage_points_wgs84\")\n",
    "if arcpy.Exists(tmp_points_wgs84):\n",
    "    arcpy.management.Delete(tmp_points_wgs84)\n",
    "\n",
    "arcpy.management.CopyFeatures(xy_layer, tmp_points_wgs84)\n",
    "\n",
    "print(\"Created WGS84 points:\", tmp_points_wgs84)\n",
    "print(\"Count:\", arcpy.management.GetCount(tmp_points_wgs84)[0])\n",
    "\n",
    "# Project to StatePlane CA VI (Feet) to match CPA\n",
    "TARGET_SR = arcpy.SpatialReference(2229)\n",
    "\n",
    "if arcpy.Exists(DRAINAGE_POINTS_FC):\n",
    "    arcpy.management.Delete(DRAINAGE_POINTS_FC)\n",
    "\n",
    "arcpy.management.Project(\n",
    "    in_dataset=tmp_points_wgs84,\n",
    "    out_dataset=DRAINAGE_POINTS_FC,\n",
    "    out_coor_system=TARGET_SR\n",
    ")\n",
    "\n",
    "# ---- CLEANUP: remove intermediate WGS84 feature class ----\n",
    "arcpy.management.Delete(tmp_points_wgs84)\n",
    "print(\"Deleted temporary WGS84 feature class\")\n",
    "\n",
    "print(\"Projected points FC:\", DRAINAGE_POINTS_FC)\n",
    "print(\"Projected SR:\", arcpy.Describe(DRAINAGE_POINTS_FC).spatialReference.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "996e2c6d-d11c-462a-b1da-371ec4553339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAD_1983_StatePlane_California_V_FIPS_0405_Feet\n",
      "NAD_1983_StatePlane_California_V_FIPS_0405_Feet\n"
     ]
    }
   ],
   "source": [
    "# Sanity check to make sure both of the layers used in the analysis are in the same projection before doing the join.\n",
    "print(arcpy.Describe(CPA_FC).spatialReference.name)\n",
    "print(arcpy.Describe(DRAINAGE_POINTS_FC).spatialReference.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01e0b8bc-aa85-41ca-8f89-3fd2c6d14d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created CPA summary FC: C:\\Users\\kris_\\OneDrive - Kris Manske\\Documents\\Classes\\BootcampGIS\\Wildfire repositories on AWS\\GetItDone\\data_working\\GetItDoneAnalysis.gdb\\gid_drainage_by_cpa\n"
     ]
    }
   ],
   "source": [
    "if arcpy.Exists(DRAINAGE_BY_CPA_FC):\n",
    "    arcpy.management.Delete(DRAINAGE_BY_CPA_FC)\n",
    "\n",
    "arcpy.analysis.SpatialJoin(\n",
    "    target_features=CPA_FC,            # polygons\n",
    "    join_features=DRAINAGE_POINTS_FC,  # points\n",
    "    out_feature_class=DRAINAGE_BY_CPA_FC,\n",
    "    join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "    join_type=\"KEEP_ALL\",\n",
    "    match_option=\"INTERSECT\"\n",
    ")\n",
    "\n",
    "print(\"Created CPA summary FC:\", DRAINAGE_BY_CPA_FC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b92c81b8-4c08-4aa1-8b91-bcbdc1d5552b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated CPA schema standardized\n"
     ]
    }
   ],
   "source": [
    "fc = DRAINAGE_BY_CPA_FC\n",
    "\n",
    "# Rename Join_Count → COMPLAINT_CNT\n",
    "fields = [f.name for f in arcpy.ListFields(fc)]\n",
    "if \"Join_Count\" in fields and \"COMPLAINT_CNT\" not in fields:\n",
    "    arcpy.management.AlterField(fc, \"Join_Count\", \"COMPLAINT_CNT\", \"COMPLAINT_CNT\")\n",
    "\n",
    "print(\"Aggregated CPA schema standardized\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
